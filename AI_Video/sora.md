参考链接：

https://openai.com/index/sora/ （OpenAI官方的报告，香港节点进不去，实测新加坡节点可以）
https://blog.mlq.ai/openai-sora-overview/ 
https://labelyourdata.com/articles/explaining-openai-sora（这篇博客中有很多示例图可以使用）
https://www.woshipm.com/aigc/6015159.html 这是一篇sora团队专访

参考视频：

https://www.bilibili.com/video/BV1Um411S7SZ/

https://www.bilibili.com/video/BV14F4m1c7RC

https://www.bilibili.com/video/BV1aC411a7pp/

## 标题：

Sora正式发布！视频生成的iPhone时刻来了！（GPT3时刻来了）

中国版的Sora还需多久？

国产AI视频生成能打过Sora吗？

Sora来了！对哪些专业有影响呢？AI时代我们怎么才能不会被AI背刺，而是利用好AI，让AI成为自己的伙伴

如何制作出山海经里的画面？

## 提问

### 事物

> sora是什么？干什么用的？应用场景？整活场景？

sora是OpenAI推出的文字生成视频的系统

宣称可以<u>最多生成60秒的视频</u>（[来源](https://x.com/OpenAI/status/1758192957386342435)）

sora受日语“天空”的启发，该模型的名字反映了其无限创造力的潜力。

首先致敬传奇吃面王威尔史密斯https://www.youtube.com/watch?v=XQr4Xklqzw8，连一刻也没有为他哀悼，立刻赶到战场的是Sora

https://www.youtube.com/watch?v=TRIrr3Aar44 进度条6分04

Sora模型最突出的地方是，它能够理解和模拟真实的物理世界，并理解物理动力学和美学。

现状：经过了“红色团队”的测试与纠错，sora马上就能上线了。

应用场景：

- 自然语言生成视频

输入简单的文本描述，比如“在沙滩上散步的男人”， AI 会理解文本中的内容、场景和意图，生成高度一致的短视频。（OpenAI油管上有很多示例，素材可以选那上面的）

- 结合图像生成技术

Sora 使用了类似 DALL-E 和其他生成模型的技术，可以生成高质量的场景、人物和物体，并将这些静态图像合成到流畅的视频中

### 技术

> sora背后有哪些技术？又是如何训练出来的？有哪些特性？

OpenAI的 **Sora** 文本生成视频模型基于先进的机器学习架构，如 **Transformer** 和 **扩散模型（Diffusion Model）**，能够从文本提示生成连贯的视频。

模型的生成过程采用 **扩散式生成**：从一开始带有噪声的图像逐步去噪，使图像逐渐逼近文本描述。Sora 类似于 OpenAI 的 DALL-E 图像生成模型，将视频帧分解成“视觉块”（visual patches），类似语言模型的“词汇单元”，这样既保证了视频的高质量输出，同时能处理各种长度、分辨率和比例的视频。

- 时序一致性

生成视频最大的挑战之一是要保持连续帧之间的时序一致性，使动作流畅。Sora 通过改进扩散模型中的时间建模，使帧与帧之间能够根据时间顺序合理变化，确保物体和背景元素在帧序列中的位置与姿态逐渐变化，以实现连贯的视频效果。

- 文本到视觉映射

模型使用了一种叫做文本到视觉映射（text-to-visual mapping）的技术，将文字描述转化为视觉特征。这种技术基于 CLIP（Contrastive Language-Image Pretraining）等模型，通过大量的跨模态数据训练，使模型能够理解“沙滩”、“日落”等语义词汇并将其映射到合适的视觉表现上。（这里的举例也可以根据最终选择的素材进行切换）

- 视频生成与融合

在生成每一帧图像后，Sora 会将这些静态图像合成为视频。在视频生成阶段，模型会利用生成对抗网络（GAN）和卷积神经网络（CNN），结合时间信息逐帧生成，从而形成自然的动作和场景转换效果。

关于训练数据：

然而，OpenAI没有透露用于Sora的训练数据的来源。

他们提到需要大量的字幕视频

Sora利用了多样化和广泛的数据集，包括不同长度、分辨率和长宽比的视频和图像。

该模型重新创建虚拟环境的能力表明，其训练数据可能包括游戏片段和来自游戏引擎的模拟。



### 思想

sora涉及的人工智能算法有哪些？



反向扩散原理通俗讲解：一滴油滴到水中，会分散开来，混合到水中，这是扩散，diffusion就是反过来，从无规则的油水混合物的状态下逆转为油水分离的情况，让整体变得有序。

画面生成技术中也是类似，先将规则的画面打乱成无规则的色块，再从这堆马赛克中，复原成有规则的图样，最终结果也可能和一开始不一致，有多种可能性，既可能是红薯，也可能是红鼠，是受到prompt提示词的形象



Transformer通俗讲解：类似于GPT中的token，将文本分成一个个单词或短语，每一个单元就被叫做token；transformer是将图片拆成小块，小块被叫做patch，因为是视频，所以存在时间的维度，是四维的数据（图片的长和宽，色彩空间，时间），通过这些patch，可以来预测出新视频

### 基础科学

这些算法需要什么数学基础？